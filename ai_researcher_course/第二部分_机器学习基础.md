# 第二部分：机器学习基础

## 第4章 机器学习概述

### 4.1 机器学习定义与分类

#### 4.1.1 机器学习的定义

**机器学习的经典定义**：
Tom Mitchell给出的定义：
```
一个计算机程序被称为从经验E中学习，如果它在任务T上的性能P，随着经验E的增加而提高。
```

**核心要素**：
- **任务（Task）**：要解决的问题
- **经验（Experience）**：训练数据
- **性能（Performance）**：评估指标
- **模型（Model）**：学习的函数

**与传统编程的区别**：
- **传统编程**：数据 + 规则 → 结果
- **机器学习**：数据 + 结果 → 规则

#### 4.1.2 机器学习的分类

**监督学习（Supervised Learning）**：
- **定义**：从标记数据中学习模式
- **输入**：特征向量X，标签Y
- **输出**：预测函数f: X → Y
- **应用**：分类、回归

**无监督学习（Unsupervised Learning）**：
- **定义**：从未标记数据中发现结构
- **输入**：特征向量X
- **输出**：数据结构或模式
- **应用**：聚类、降维、异常检测

**强化学习（Reinforcement Learning）**：
- **定义**：通过与环境交互学习最优策略
- **要素**：状态、动作、奖励
- **目标**：最大化累积奖励
- **应用**：游戏AI、机器人控制

**半监督学习（Semi-supervised Learning）**：
- **定义**：结合标记和未标记数据
- **优势**：减少标记成本
- **应用**：图像识别、文本分类

#### 4.1.3 机器学习的工作流程

**典型流程**：
```
1. 问题定义
2. 数据收集与预处理
3. 特征工程
4. 模型选择与训练
5. 模型评估
6. 模型部署与监控
```

**数据预处理**：
- **数据清洗**：处理缺失值、异常值
- **数据变换**：标准化、归一化
- **特征选择**：选择重要特征
- **特征构造**：创建新特征

**模型开发循环**：
- **训练**：在训练数据上学习
- **验证**：在验证数据上调参
- **测试**：在测试数据上评估
- **迭代**：根据结果改进

#### 4.1.4 机器学习的应用领域

**计算机视觉**：
- **图像分类**：识别图像内容
- **目标检测**：定位并识别物体
- **图像分割**：像素级分类
- **人脸识别**：身份验证

**自然语言处理**：
- **文本分类**：情感分析、主题分类
- **机器翻译**：语言间的转换
- **问答系统**：回答自然语言问题
- **文本生成**：自动生成文本

**推荐系统**：
- **个性化推荐**：基于用户偏好
- **协同过滤**：基于用户相似性
- **内容推荐**：基于内容相似性
- **混合推荐**：结合多种方法

**金融应用**：
- **信用评分**：评估信用风险
- **欺诈检测**：识别异常交易
- **算法交易**：自动交易策略
- **风险管理**：量化风险

### 4.2 监督学习

#### 4.2.1 监督学习基本概念

**监督学习的数学表示**：
```
给定训练数据：D = {(x₁, y₁), (x₂, y₂), ..., (xₙ, yₙ)}
其中xᵢ ∈ ℝᵈ为特征向量，yᵢ为标签

学习函数：f: ℝᵈ → Y，使得f(x) ≈ y
```

**损失函数（Loss Function）**：
衡量预测值与真实值的差距：
```
回归损失：L(y, ŷ) = (y - ŷ)²
分类损失：L(y, ŷ) = -y log(ŷ) - (1-y) log(1-ŷ)
```

**经验风险最小化**：
```
min θ (1/n) Σᵢ L(yᵢ, f(xᵢ; θ))
```

**结构风险最小化**：
```
min θ (1/n) Σᵢ L(yᵢ, f(xᵢ; θ)) + λR(θ)
```

#### 4.2.2 回归问题

**回归任务定义**：
预测连续值的目标变量。

**线性回归**：
```
模型：y = β₀ + β₁x₁ + ... + βₚxₚ + ε
损失函数：L = Σ(yᵢ - ŷᵢ)²
```

**多项式回归**：
```
y = β₀ + β₁x + β₂x² + ... + βₖxᵏ + ε
```

**正则化回归**：
- **Ridge回归**：L2正则化
- **Lasso回归**：L1正则化
- **Elastic Net**：L1+L2正则化

#### 4.2.3 分类问题

**二分类**：
标签y ∈ {0, 1}，预测概率P(y=1|x)。

**多分类**：
标签y ∈ {1, 2, ..., K}，预测每个类别的概率。

**常用分类算法**：
- **逻辑回归**：线性分类器
- **决策树**：基于规则的分类
- **支持向量机**：最大间隔分类
- **神经网络**：复杂非线性分类

**分类评估指标**：
- **准确率**：(TP + TN) / (TP + TN + FP + FN)
- **精确率**：TP / (TP + FP)
- **召回率**：TP / (TP + FN)
- **F1分数**：2 × (精确率 × 召回率) / (精确率 + 召回率)

#### 4.2.4 监督学习的实践考虑

**数据划分**：
- **训练集**：模型训练
- **验证集**：超参数调优
- **测试集**：最终评估

**交叉验证**：
```
k折交叉验证：
1. 将数据分为k个子集
2. 轮流使用k-1个子集训练，1个子集验证
3. 计算平均性能
```

**过拟合与欠拟合**：
- **过拟合**：模型复杂度过高，训练误差小但测试误差大
- **欠拟合**：模型复杂度过低，训练误差和测试误差都大
- **解决方案**：正则化、交叉验证、早停

### 4.3 无监督学习

#### 4.3.1 无监督学习概述

**无监督学习的目标**：
从未标记数据中发现有意义的结构或模式。

**主要任务类型**：
- **聚类（Clustering）**：将相似数据分组
- **降维（Dimensionality Reduction）**：减少特征数量
- **异常检测（Anomaly Detection）**：识别异常数据点
- **关联规则（Association Rules）**：发现变量间关系

**挑战**：
- 缺乏明确的评估标准
- 结果解释性差
- 需要领域知识验证

#### 4.3.2 聚类算法

**K-means聚类**：
```
算法步骤：
1. 随机选择k个中心点
2. 将每个点分配到最近的中心
3. 重新计算中心点
4. 重复2-3直到收敛
```

**层次聚类**：
- **凝聚方法**：自底向上合并
- **分裂方法**：自顶向下分裂
- **树状图**：显示聚类层次

**密度聚类（DBSCAN）**：
- 基于密度的聚类
- 可以发现任意形状的簇
- 自动确定簇的数量

**高斯混合模型（GMM）**：
```
假设数据来自多个高斯分布的混合：
p(x) = Σᵢ πᵢ N(x|μᵢ, Σᵢ)
其中πᵢ为混合权重
```

#### 4.3.3 降维技术

**主成分分析（PCA）**：
```
目标：找到最大化方差的方向
步骤：
1. 标准化数据
2. 计算协方差矩阵
3. 求特征值和特征向量
4. 选择前k个主成分
```

**t-SNE（t-Distributed Stochastic Neighbor Embedding）**：
- 非线性降维
- 保持局部结构
- 适合可视化

**自编码器（Autoencoder）**：
- 神经网络架构
- 编码器-解码器结构
- 学习数据的低维表示

#### 4.3.4 异常检测

**统计方法**：
- **Z-score**：基于标准差
- **IQR方法**：基于四分位数
- **高斯分布**：基于概率密度

**基于距离的方法**：
- **KNN**：基于最近邻距离
- **LOF**：局部异常因子
- **DBSCAN**：基于密度

**基于模型的方法**：
- **One-Class SVM**：单类支持向量机
- **Isolation Forest**：孤立森林
- **Autoencoder**：基于重构误差

### 4.4 强化学习基础

#### 4.4.1 强化学习基本概念

**强化学习要素**：
- **智能体（Agent）**：学习的主体
- **环境（Environment）**：智能体交互的对象
- **状态（State）**：环境的描述
- **动作（Action）**：智能体的行为
- **奖励（Reward）**：动作的反馈

**马尔可夫决策过程（MDP）**：
```
MDP = (S, A, P, R, γ)
其中：
S：状态空间
A：动作空间
P：状态转移概率
R：奖励函数
γ：折扣因子
```

**价值函数**：
- **状态价值**：V(s) = E[Σᵗ γᵗ rₜ | s₀ = s]
- **动作价值**：Q(s,a) = E[Σᵗ γᵗ rₜ | s₀ = s, a₀ = a]

#### 4.4.2 值函数方法

**动态规划**：
- **值迭代**：迭代更新价值函数
- **策略迭代**：交替改进策略和价值

**蒙特卡洛方法**：
- 基于完整的轨迹采样
- 无需环境模型
- 方差大，无偏

**时序差分（TD）方法**：
- 基于时间差分学习
- 在线学习
- 方差小，有偏

#### 4.4.3 策略梯度方法

**策略函数**：
π(a|s; θ)：在状态s下选择动作a的概率。

**策略梯度定理**：
```
∇θ J(θ) = E[∇θ log π(a|s; θ) Q(s,a)]
```

**REINFORCE算法**：
```
1. 采集轨迹：s₀, a₀, r₁, s₁, a₁, ..., sₜ
2. 计算回报：Gₜ = Σᵢ γⁱ rₜ₊ᵢ
3. 更新策略：θ ← θ + α∇θ log π(aₜ|sₜ; θ) Gₜ
```

**Actor-Critic方法**：
- **Actor**：策略网络
- **Critic**：价值网络
- 结合策略梯度和值函数方法

#### 4.4.4 深度强化学习

**深度Q网络（DQN）**：
- 使用神经网络近似Q函数
- 经验回放
- 目标网络
- ε-greedy探索

**策略梯度网络**：
- **A3C**：异步优势Actor-Critic
- **PPO**：近端策略优化
- **TRPO**：信任区域策略优化

**应用场景**：
- **游戏AI**：AlphaGo、OpenAI Five
- **机器人控制**：机械臂控制、自动驾驶
- **推荐系统**：个性化推荐
- **资源管理**：云计算资源调度

## 第5章 经典机器学习算法

### 5.1 线性回归与逻辑回归

#### 5.1.1 线性回归基础

**线性回归模型**：
```
简单线性回归：y = β₀ + β₁x + ε
多元线性回归：y = β₀ + β₁x₁ + ... + βₚxₚ + ε
```

**最小二乘法**：
目标是最小化残差平方和：
```
min β Σᵢ (yᵢ - β₀ - Σⱼ βⱼxᵢⱼ)²
```

**正规方程解**：
```
β = (XᵀX)⁻¹Xᵀy
```

**梯度下降解**：
```
βⱼ := βⱼ - α(1/n)Σᵢ (hβ(xᵢ) - yᵢ)xᵢⱼ
```

#### 5.1.2 正则化线性回归

**Ridge回归（L2正则化）**：
```
目标函数：min β ||y - Xβ||² + λ||β||²
解：β = (XᵀX + λI)⁻¹Xᵀy
```

**Lasso回归（L1正则化**）：

```
目标函数：min β ||y - Xβ||² + λ||β||₁
特点：产生稀疏解，可用于特征选择
```

**Elastic Net**：

```
目标函数：min β ||y - Xβ||² + λ₁||β||₁ + λ₂||β||²
结合L1和L2正则化的优点
```

#### 5.1.3 逻辑回归

**逻辑回归模型**：
```
二分类逻辑回归：
P(y=1|x) = 1 / (1 + exp(-(β₀ + β₁x₁ + ... + βₚxₚ)))

多分类逻辑回归（Softmax）：
P(y=k|x) = exp(βₖᵀx) / Σⱼ exp(βⱼᵀx)
```

**损失函数（交叉熵）**：
```
二分类：L = -Σᵢ [yᵢ log(pᵢ) + (1-yᵢ) log(1-pᵢ)]
多分类：L = -Σᵢ Σₖ yᵢₖ log(pᵢₖ)
```

**梯度下降更新**：
```
βⱼ := βⱼ - α(1/n)Σᵢ (hβ(xᵢ) - yᵢ)xᵢⱼ
```

#### 5.1.4 实践技巧

**特征缩放**：
- **标准化**：(x - μ)/σ
- **归一化**：(x - min)/(max - min)
- **为什么需要**：梯度下降收敛更快

**多项式特征**：
```
原始特征：[x₁, x₂]
二次特征：[x₁, x₂, x₁², x₂², x₁x₂]
```

**交互特征**：
捕捉特征间的交互作用：
```
交互特征：[x₁, x₂, x₁×x₂]
```

**处理分类变量**：
- **独热编码**：One-Hot Encoding
- **标签编码**：Label Encoding
- **目标编码**：Target Encoding

### 5.2 决策树与随机森林

#### 5.2.1 决策树基础

**决策树结构**：
- **根节点**：包含所有样本
- **内部节点**：基于特征分割
- **叶节点**：做出预测
- **分支**：分割条件

**分割准则**：
**信息增益（ID3）**：
```
信息熵：H(S) = -Σₚ pᵢ log₂ pᵢ
信息增益：IG(S,A) = H(S) - Σ|Sᵥ|/|S| H(Sᵥ)
```

**信息增益比（C4.5）**：
```
增益比：GR(S,A) = IG(S,A) / H(A)
```

**Gini指数（CART）**：
```
Gini指数：Gini(S) = 1 - Σₚ pᵢ²
Gini增益：ΔGini = Gini(S) - Σ|Sᵥ|/|S| Gini(Sᵥ)
```

**决策树构建算法**：
```
1. 选择最佳分割特征和阈值
2. 根据分割条件将数据分成子集
3. 递归地对每个子集构建子树
4. 停止条件：达到最大深度、节点样本数过少、纯度高
```

#### 5.2.2 决策树的优化

**剪枝策略**：
- **预剪枝**：在构建过程中停止
  - 最大深度
  - 最小样本数
  - 最小信息增益

- **后剪枝**：构建完成后剪枝
  - 降低错误率剪枝
  - 成本复杂度剪枝

**连续变量处理**：
- 寻找最佳分割点
- 二分法处理连续变量

**缺失值处理**：
- **代理分割**：使用替代特征
- **权重调整**：调整样本权重
- **单独处理**：将缺失值单独分支

#### 5.2.3 随机森林

**随机森林原理**：
```
随机森林 = 决策树 + Bagging + 随机特征选择
```

**构建过程**：
1. **Bootstrap采样**：有放回抽样
2. **随机特征选择**：每棵树使用随机特征子集
3. **构建决策树**：构建完整的决策树
4. **集成预测**：投票或平均

**超参数**：
- **n_estimators**：树的数量
- **max_depth**：最大深度
- **max_features**：每棵树使用的特征数
- **min_samples_split**：分割最小样本数

**特征重要性**：
```
重要性 = 基于特征分割的节点不纯度减少总和
```

#### 5.2.4 梯度提升树

**梯度提升原理**：
```
F₀(x) = argmin c Σᵢ L(yᵢ, c)
for m = 1 to M:
    rᵢₘ = -[∂L(yᵢ, F(xᵢ))/∂F(xᵢ)]_{F(x)=Fₘ₋₁(x)}
    aₘ = argmin α,γ Σᵢ L(yᵢ, Fₘ₋₁(xᵢ) + αh(xᵢ;γ))
    ρₘ = argmin ρ Σᵢ L(yᵢ, Fₘ₋₁(xᵢ) + ρh(xᵢ;aₘ))
    Fₘ(x) = Fₘ₋₁(x) + ρₘ h(x;aₘ)
```

**XGBoost**：
- 二阶泰勒展开
- 正则化项
- 缺失值处理
- 并行计算

**LightGBM**：
- 基于梯度的单边采样
- 互斥特征捆绑
- 叶子生长策略

**CatBoost**：
- 目标编码
- 类别特征处理
- 过拟合检测

### 5.3 支持向量机

#### 5.3.1 SVM基本概念

**最大间隔分类器**：
寻找能够最大化分类间隔的超平面。

**几何间隔**：
```
点到超平面的距离：|w·x + b|/||w||
几何间隔：γ = y(w·x + b)/||w||
```

**支持向量**：
位于间隔边界上的样本点。

**优化问题**：
```
min w,b (1/2)||w||²
s.t. yᵢ(w·xᵢ + b) ≥ 1, ∀i
```

#### 5.3.2 核方法

**核函数原理**：
将数据映射到高维空间，使其在高维空间中线性可分。

**常用核函数**：
- **线性核**：K(x, z) = x·z
- **多项式核**：K(x, z) = (x·z + c)ᵈ
- **高斯核（RBF）**：K(x, z) = exp(-γ||x-z||²)
- **Sigmoid核**：K(x, z) = tanh(αx·z + β)

**核技巧**：
不需要显式计算特征映射，只需计算核函数。

** Mercer条件**：
核函数必须是正定的。

#### 5.3.3 软间隔SVM

**松弛变量**：
```
min w,b,ξ (1/2)||w||² + CΣᵢ ξᵢ
s.t. yᵢ(w·xᵢ + b) ≥ 1 - ξᵢ, ξᵢ ≥ 0, ∀i
```

**对偶问题**：
```
max α Σᵢ αᵢ - (1/2)Σᵢⱼ αᵢαⱼyᵢyⱼK(xᵢ,xⱼ)
s.t. 0 ≤ αᵢ ≤ C, Σᵢ αᵢyᵢ = 0
```

**支持向量回归（SVR）**：
```
min w,b,ξ,ξ* (1/2)||w||² + CΣᵢ(ξᵢ + ξᵢ*)
s.t. yᵢ - (w·xᵢ + b) ≤ ε + ξᵢ
      (w·xᵢ + b) - yᵢ ≤ ε + ξᵢ*
      ξᵢ, ξᵢ* ≥ 0
```

#### 5.3.4 SVM的优化算法

**序列最小优化（SMO）**：
1. 选择两个拉格朗日乘子进行优化
2. 解析求解二维优化问题
3. 重复直到收敛

**分解算法**：
将大规模问题分解为小规模子问题。

**并行化算法**：
- 并行计算核矩阵
- 分布式优化
- GPU加速

### 5.4 集成学习方法

#### 5.4.1 Bagging方法

**Bagging原理**：
Bootstrap Aggregating，通过对训练数据进行有放回抽样，训练多个基学习器，然后进行投票或平均。

**随机森林**：
```
构建过程：
1. Bootstrap采样得到n个训练集
2. 每个训练集构建一棵决策树
3. 构建时随机选择特征
4. 集成所有树的预测结果
```

**Extra Trees**：
- 随机选择分割点和特征
- 更大的随机性
- 更好的多样性

**Bagging的变体**：
- **Pasting**：无放回抽样
- **Random Subspaces**：随机选择特征子空间
- **Random Patches**：随机选择样本和特征

#### 5.4.2 Boosting方法

**AdaBoost**：
```
1. 初始化样本权重：wᵢ = 1/n
2. 对于每个弱学习器：
   - 训练弱学习器hₜ
   - 计算错误率：εₜ = Σᵢ wᵢ I(yᵢ ≠ hₜ(xᵢ))
   - 计算权重：αₜ = (1/2)ln((1-εₜ)/εₜ)
   - 更新权重：wᵢ ← wᵢ exp(-αₜ yᵢ hₜ(xᵢ))
   - 归一化权重
3. 最终预测：H(x) = sign(Σₜ αₜ hₜ(x))
```

**Gradient Boosting**：
```
使用梯度下降来训练弱学习器：
F₀(x) = argmin_c Σᵢ L(yᵢ, c)
for m = 1 to M:
    rᵢₘ = -∂L(yᵢ, Fₘ₋₁(xᵢ))/∂Fₘ₋₁(xᵢ)
    hₘ = argmin_h Σᵢ (rᵢₘ - h(xᵢ))²
    γₘ = argmin_γ Σᵢ L(yᵢ, Fₘ₋₁(xᵢ) + γhₘ(xᵢ))
    Fₘ(x) = Fₘ₋₁(x) + γₘ hₘ(x)
```

#### 5.4.3 Stacking方法

**Stacking原理**：
将多个基学习器的预测作为输入，训练一个元学习器来做出最终预测。

**Stacking结构**：
```
Level 0：基学习器（决策树、SVM、神经网络等）
Level 1：元学习器（逻辑回归、线性回归等）
```

**Stacking的变体**：
- **Blending**：使用验证集而非交叉验证
- **Stacking with CV**：使用交叉验证生成元特征
- **Multi-level Stacking**：多层 stacking

#### 5.4.4 集成学习的实践

**基学习器选择**：
- **多样性**：不同类型的算法
- **准确性**：基学习器要有一定准确性
- **独立性**：减少相关性

**集成策略**：
- **投票**：多数投票或加权投票
- **平均**：简单平均或加权平均
- **Stacking**：学习集成权重

**防止过拟合**：
- **交叉验证**：在验证集上评估
- **正则化**：限制基学习器复杂度
- **早停**：防止过度训练

## 第6章 模型评估与选择

### 6.1 交叉验证

#### 6.1.1 交叉验证的基本概念

**交叉验证的目的**：
- 评估模型泛化性能
- 选择最佳模型
- 调整超参数
- 防止过拟合

**数据划分策略**：
- **训练集**：用于模型训练
- **验证集**：用于模型选择
- **测试集**：用于最终评估

#### 6.1.2 常用交叉验证方法

**K折交叉验证**：
```
算法步骤：
1. 将数据随机分成K个大小相等的子集
2. 每次使用K-1个子集作为训练集，1个子集作为验证集
3. 重复K次，每个子集都作为验证集一次
4. 计算K次验证结果的平均值
```

**留一交叉验证（LOOCV）**：
- K = n的特殊情况
- 每次只留一个样本作为验证
- 计算成本高，评估准确

**分层K折交叉验证**：
保持每个折中各类别的比例与原始数据相同。

**时间序列交叉验证**：
```
对于时间序列数据：
训练集：[0, t]
验证集：[t+1, t+k]
不能随机打乱时间顺序
```

#### 6.1.3 交叉验证的变体

**重复K折交叉验证**：
重复进行多次K折交叉验证，得到更稳定的评估。

**嵌套交叉验证**：
```
外层循环：模型评估
内层循环：超参数调优
防止数据泄露和过拟合
```

**分组交叉验证**：
保持相关样本在同一折中，如医疗数据中的患者。

#### 6.1.4 交叉验证的实践考虑

**K值选择**：
- **K=5或10**：常用选择
- **K较小**：计算效率高，偏差大
- **K较大**：计算成本高，偏差小

**数据量影响**：
- **大数据集**：可以使用较小的K
- **小数据集**：需要较大的K或LOOCV

**计算效率**：
- **并行计算**：可以并行执行各折
- **早停**：基于验证集性能早停
- **缓存**：缓存中间结果

### 6.2 性能度量指标

#### 6.2.1 分类指标

**混淆矩阵**：
```
              预测正例    预测反例
实际正例     TP（真正例） FN（假反例）
实际反例     FP（假正例） TN（真反例）
```

**基本指标**：
- **准确率**：(TP + TN) / (TP + TN + FP + FN)
- **精确率**：TP / (TP + FP)
- **召回率（灵敏度）**：TP / (TP + FN)
- **特异性**：TN / (TN + FP)

**F1分数**：
```
F1 = 2 × (精确率 × 召回率) / (精确率 + 召回率)
```

**ROC曲线与AUC**：
- **ROC曲线**：真正例率 vs 假正例率
- **AUC**：ROC曲线下的面积
- **优点**：不依赖于分类阈值

#### 6.2.2 回归指标

**均方误差（MSE）**：
```
MSE = (1/n) Σᵢ (yᵢ - ŷᵢ)²
```

**均方根误差（RMSE）**：
```
RMSE = √MSE
```

**平均绝对误差（MAE）**：
```
MAE = (1/n) Σᵢ |yᵢ - ŷᵢ|
```

**决定系数（R²）**：
```
R² = 1 - Σᵢ (yᵢ - ŷᵢ)² / Σᵢ (yᵢ - ȳ)²
```

#### 6.2.3 聚类指标

**轮廓系数**：
```
对于每个样本i：
aᵢ = 样本i到同簇其他样本的平均距离
bᵢ = 样本i到最近簇样本的平均距离
轮廓系数：sᵢ = (bᵢ - aᵢ) / max(aᵢ, bᵢ)
```

**Davies-Bouldin指数**：
```
DB = (1/k) Σᵢ max_{j≠i} [(σᵢ + σⱼ) / d(cᵢ, cⱼ)]
其中σᵢ为簇i的分散度，d(cᵢ, cⱼ)为簇间距离
```

**Calinski-Harabasz指数**：
```
CH = [Σₖ nₖ(cₖ - c)²/(k-1)] / [Σₖ Σᵢ∈Cₖ ||xᵢ - cₖ||²/(n-k)]
```

#### 6.2.4 排序与推荐指标

**Precision@K**：
前K个推荐中相关项目的比例。

**Recall@K**：
前K个推荐中覆盖的相关项目比例。

**MAP@K（Mean Average Precision）**：
```
AP@K = Σₖ Precision@k × rel(k)
MAP@K = (1/|Q|) Σ_q AP@K(q)
```

**NDCG@K（Normalized Discounted Cumulative Gain）**：
```
DCG@K = Σₖ (2^{rel(k)} - 1) / log₂(k+1)
NDCG@K = DCG@K / IDCG@K
```

### 6.3 偏差-方差权衡

#### 6.3.1 偏差与方差的定义

**偏差（Bias）**：
模型预测值与真实值的差距：
```
Bias = E[ŷ] - y
```

**方差（Variance）**：
模型预测值的波动程度：
```
Variance = E[(ŷ - E[ŷ])²]
```

**不可约误差（Irreducible Error）**：
数据本身的噪声：
```
ε = y - f(x)
```

**总误差分解**：
```
Expected Error = Bias² + Variance + Irreducible Error
```

#### 6.3.2 偏差-方差权衡

**高偏差（欠拟合）**：
- **特征**：模型过于简单
- **表现**：训练误差和测试误差都很大
- **解决**：增加模型复杂度、添加特征

**高方差（过拟合）**：
- **特征**：模型过于复杂
- **表现**：训练误差小，测试误差大
- **解决**：减少模型复杂度、增加数据、正则化

**权衡策略**：
```
寻找模型复杂度的最佳平衡点：
- 简单模型：高偏差，低方差
- 复杂模型：低偏差，高方差
- 最佳模型：偏差和方差都适中
```

#### 6.3.3 学习曲线

**学习曲线定义**：
训练集大小与模型性能的关系曲线。

**高偏差学习曲线**：
- 训练误差和验证误差都较高
- 两条曲线接近且都较高
- 增加数据帮助不大

**高方差学习曲线**：
- 训练误差低，验证误差高
- 两条曲线差距大
- 增加数据可能帮助

**理想学习曲线**：
- 训练误差和验证误差都较低
- 两条曲线接近且都较低
- 随着数据增加，性能继续改善

#### 6.3.4 实践中的偏差-方差分析

**诊断方法**：
- **交叉验证**：评估模型泛化性能
- **学习曲线**：分析偏差-方差状况
- **验证曲线**：分析超参数影响

**改善偏差的方法**：
- 增加特征或多项式特征
- 减少正则化强度
- 使用更复杂的模型
- 增加训练时间

**改善方差的方法**：
- 增加训练数据
- 减少特征数量
- 增加正则化强度
- 使用集成方法
- 早停（对于神经网络）

### 6.4 模型选择策略

#### 6.4.1 模型比较方法

**成对比较**：
- McNemar检验：比较两个分类器
- t检验：比较回归模型
- Wilcoxon符号秩检验：非参数比较

**多重比较**：
- ANOVA：比较多个模型
- Friedman检验：非参数多重比较
- Nemenyi检验：事后检验

**贝叶斯模型比较**：
```
后验概率：P(M|D) ∝ P(D|M)P(M)
贝叶斯因子：B₁₂ = P(D|M₁)/P(D|M₂)
```

#### 6.4.2 超参数调优

**网格搜索（Grid Search）**：
```
在预定义的超参数网格中搜索最佳组合：
for α in [0.1, 1, 10]:
    for β in [0.01, 0.1, 1]:
        train model with (α, β)
        evaluate using cross-validation
```

**随机搜索（Random Search）**：
- 在超参数空间中随机采样
- 比网格搜索更高效
- 适合高维超参数空间

**贝叶斯优化**：
- 使用高斯过程建模目标函数
- 平衡探索和利用
- 适合计算昂贵的模型

#### 6.4.3 自动机器学习

**AutoML工具**：
- **Auto-sklearn**：基于scikit-learn
- **TPOT**：遗传算法优化
- **H2O AutoML**：企业级AutoML
- **AutoKeras**：神经网络自动设计

**AutoML组件**：
- **数据预处理**：自动特征工程
- **模型选择**：自动选择最佳模型
- **超参数优化**：自动调参
- **集成方法**：自动集成

**挑战与局限**：
- 计算成本高
- 可解释性差
- 需要领域知识验证

#### 6.4.4 模型选择最佳实践

**数据划分策略**：
```
训练集（60%）：模型训练
验证集（20%）：模型选择和调参
测试集（20%）：最终评估
```

**选择流程**：
1. 基于问题类型选择候选模型
2. 使用交叉验证评估性能
3. 调整超参数
4. 选择最佳模型
5. 在测试集上最终评估

**考虑因素**：
- **性能**：模型准确性和泛化能力
- **可解释性**：模型的可解释性要求
- **计算效率**：训练和预测速度
- **维护成本**：模型部署和维护成本